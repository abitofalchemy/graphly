{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MINST Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Elemwise{exp,no_inplace}(<TensorType(float64, vector)>)]\n",
      "Looping 1000 times took 1.554433 seconds\n",
      "Result is [ 1.23178032  1.61879341  1.52278065 ...,  2.20771815  2.29967753\n",
      "  1.62323285]\n",
      "Used the cpu\n"
     ]
    }
   ],
   "source": [
    "# Test if the system is GPU capable\n",
    "from theano import function, config, shared, sandbox\n",
    "import theano.tensor as T\n",
    "import numpy\n",
    "import time\n",
    "\n",
    "vlen = 10 * 30 * 768  # 10 x #cores x # threads per core\n",
    "iters = 1000\n",
    "\n",
    "rng = numpy.random.RandomState(22)\n",
    "x = shared(numpy.asarray(rng.rand(vlen), config.floatX))\n",
    "f = function([], T.exp(x))\n",
    "print(f.maker.fgraph.toposort())\n",
    "t0 = time.time()\n",
    "for i in range(iters):\n",
    "    r = f()\n",
    "t1 = time.time()\n",
    "print(\"Looping %d times took %f seconds\" % (iters, t1 - t0))\n",
    "print(\"Result is %s\" % (r,))\n",
    "if numpy.any([isinstance(x.op, T.Elemwise) for x in f.maker.fgraph.toposort()]):\n",
    "    print('Used the cpu')\n",
    "else:\n",
    "    print('Used the gpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n"
     ]
    }
   ],
   "source": [
    "import cPickle, gzip\n",
    "import numpy as np\n",
    "import theano\n",
    "\n",
    "\n",
    "#############\n",
    "# LOAD DATA #\n",
    "#############\n",
    "# Load the dataset\n",
    "print('... loading data')\n",
    "f = gzip.open(\"./data/mnist.pkl.gz\", \"rb\")\n",
    "# train_set, valid_set, test_set = cPickle.load(f)\n",
    "try:\n",
    "    train_set, valid_set, test_set = cPickle.load(f, encoding='latin1')\n",
    "except:\n",
    "    train_set, valid_set, test_set = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# store your data and how to access a minibatch\n",
    "def shared_dataset(data_xy):\n",
    "    \"\"\" Function that loads the dataset into shared variables\n",
    "    The reason we store our dataset in shared variables is to allow\n",
    "    Theano to copy it into the GPU memory (when code is run on GPU).\n",
    "    Since copying data into the GPU is slow, copying a minibatch everytime\n",
    "    is needed (the default behaviour if the data is not in a shared\n",
    "    variable) would lead to a large decrease in performance.\n",
    "    \"\"\"\n",
    "    data_x, data_y = data_xy\n",
    "    shared_x = theano.shared(np.asarray(data_x, dtype=theano.config.floatX)) \n",
    "    shared_y = theano.shared(np.asarray(data_y, dtype=theano.config.floatX)) # When storing data on the GPU it has to be stored as floats\n",
    "    # therefore we will store the labels as ‘‘floatX‘‘ as well\n",
    "    # (‘‘shared_y‘‘ does exactly that). But during our computations\n",
    "    # we need them as ints (we use labels as index, and if they are\n",
    "    # floats it doesn’t make sense) therefore instead of returning\n",
    "    # ‘‘shared_y‘‘ we will have to cast it to int. This little hack\n",
    "    # lets us get around this issue\n",
    "    return shared_x, T.cast(shared_y, 'int32')\n",
    "\n",
    "test_set_x, test_set_y = shared_dataset(test_set)\n",
    "valid_set_x, valid_set_y = shared_dataset(valid_set)\n",
    "train_set_x, train_set_y = shared_dataset(train_set)\n",
    "batch_size = 500 # size of the minibatch\n",
    "\n",
    "# accessing the third minibatch of the training set\n",
    "data  = train_set_x[2 * batch_size: 3 * batch_size]\n",
    "label = train_set_y[2 * batch_size: 3 * batch_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Optimization for Deep Learning \n",
    "\n",
    "Supervised learning for classfication models and minibatch stochastic \n",
    "gradient descent used for fine-tuning many of the DLmodels.\n",
    "\n",
    "- Zero-One Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# zero_one_loss is a Theano variable representing a symbolic\n",
    "# expression of the zero one loss ; to get the actual value this\n",
    "# symbolic expression has to be compiled into a Theano function (see \n",
    "# the Theano tutorial for more details)\n",
    "# f(x) = argmax_kP(Y |x,\\Theta)\n",
    "# where y = \\Theta\n",
    "\n",
    "zero_one_loss = T.sum(T.neq(T.argmax(p_y_given_x), y))\n",
    "\n",
    "# NLL is a symbolic variable ; to get the actual value of NLL, this symbolic # expression has to be compiled into a Theano function (see the Theano\n",
    "# tutorial for more details)\n",
    "NLL = -T.sum(T.log(p_y_given_x)[T.arange(y.shape[0]), y])\n",
    "# note on syntax: T.arange(y.shape[0]) is a vector of integers [0,1,2,...,len(y)].\n",
    "# Indexing a matrix M by the two vectors [0,1,...,K], [a,b,...,k] returns the\n",
    "# elements M[0,a], M[1,b], ..., M[K,k] as a vector.  Here, we use this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
